{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qb4745/evaluacion_1_deep_learning/blob/main/evaluacion_1_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# MLP para Fashion MNIST\n",
        "# ===============================\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "# -------------------------------\n",
        "# Parámetros globales\n",
        "# -------------------------------\n",
        "num_classes = 10         # Número de clases de salida (0-9)\n",
        "input_shape = (28, 28, 1)  # Forma de entrada para cada imagen\n",
        "batch_size = 128         # Tamaño de lote\n",
        "epochs = 15              # Número de épocas de entrenamiento\n",
        "learning_rate = 0.001    # Tasa de aprendizaje para el optimizador\n",
        "\n",
        "# -------------------------------\n",
        "# Carga y preprocesamiento de datos\n",
        "# -------------------------------\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Escalar imágenes a rango [0,1] y añadir dimensión de canal\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test  = x_test.astype(\"float32\")  / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test  = np.expand_dims(x_test, -1)\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape}, {x_train.shape[0]} muestras\")\n",
        "print(f\"x_test  shape: {x_test.shape}, {x_test.shape[0]} muestras\")\n",
        "\n",
        "# One-hot encoding de etiquetas\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# -------------------------------\n",
        "# Definición del modelo MLP\n",
        "# -------------------------------\n",
        "model = keras.Sequential(name=\"mlp_fashion_mnist\")\n",
        "model.add(layers.Flatten(input_shape=input_shape))  # Aplanar entrada\n",
        "model.add(layers.Dense(128, activation=\"relu\", name=\"hidden_layer_1\"))\n",
        "model.add(layers.Dropout(0.5, name=\"dropout_1\"))\n",
        "model.add(layers.Dense(64, activation=\"relu\", name=\"hidden_layer_2\"))\n",
        "model.add(layers.Dropout(0.5, name=\"dropout_2\"))\n",
        "model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# -------------------------------\n",
        "# Compilación del modelo\n",
        "# -------------------------------\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "print(\"Modelo compilado con éxito.\")\n",
        "\n",
        "# -------------------------------\n",
        "# Entrenamiento del modelo\n",
        "# -------------------------------\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# Evaluación en el conjunto de prueba\n",
        "# -------------------------------\n",
        "print(\"\\nEvaluando en conjunto de prueba:\")\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test loss: {score[0]:.4f}\")\n",
        "print(f\"Test accuracy: {score[1]:.4f}\")\n"
      ],
      "metadata": {
        "id": "8m0cI4rqDWL4",
        "outputId": "d88dce99-c2a1-4de0-8d2b-9068568f1e7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1), 60000 muestras\n",
            "x_test  shape: (10000, 28, 28, 1), 10000 muestras\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"mlp_fashion_mnist\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_fashion_mnist\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ hidden_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo compilado con éxito.\n",
            "Epoch 1/15\n",
            "422/422 - 62s - 147ms/step - accuracy: 0.6739 - loss: 0.9229 - val_accuracy: 0.8172 - val_loss: 0.4948\n",
            "Epoch 2/15\n",
            "422/422 - 2s - 5ms/step - accuracy: 0.7898 - loss: 0.6046 - val_accuracy: 0.8352 - val_loss: 0.4538\n",
            "Epoch 3/15\n",
            "422/422 - 2s - 5ms/step - accuracy: 0.8088 - loss: 0.5433 - val_accuracy: 0.8507 - val_loss: 0.4133\n",
            "Epoch 4/15\n",
            "422/422 - 3s - 6ms/step - accuracy: 0.8237 - loss: 0.5066 - val_accuracy: 0.8553 - val_loss: 0.3996\n",
            "Epoch 5/15\n",
            "422/422 - 3s - 8ms/step - accuracy: 0.8312 - loss: 0.4832 - val_accuracy: 0.8553 - val_loss: 0.3947\n",
            "Epoch 6/15\n",
            "422/422 - 2s - 5ms/step - accuracy: 0.8351 - loss: 0.4671 - val_accuracy: 0.8652 - val_loss: 0.3749\n",
            "Epoch 7/15\n",
            "422/422 - 2s - 6ms/step - accuracy: 0.8414 - loss: 0.4581 - val_accuracy: 0.8648 - val_loss: 0.3676\n",
            "Epoch 8/15\n",
            "422/422 - 3s - 6ms/step - accuracy: 0.8449 - loss: 0.4383 - val_accuracy: 0.8657 - val_loss: 0.3635\n",
            "Epoch 9/15\n",
            "422/422 - 2s - 5ms/step - accuracy: 0.8471 - loss: 0.4368 - val_accuracy: 0.8547 - val_loss: 0.3939\n",
            "Epoch 10/15\n",
            "422/422 - 3s - 7ms/step - accuracy: 0.8504 - loss: 0.4259 - val_accuracy: 0.8638 - val_loss: 0.3603\n",
            "Epoch 11/15\n",
            "422/422 - 2s - 6ms/step - accuracy: 0.8522 - loss: 0.4188 - val_accuracy: 0.8725 - val_loss: 0.3479\n",
            "Epoch 12/15\n",
            "422/422 - 2s - 5ms/step - accuracy: 0.8525 - loss: 0.4122 - val_accuracy: 0.8723 - val_loss: 0.3490\n",
            "Epoch 13/15\n",
            "422/422 - 3s - 6ms/step - accuracy: 0.8531 - loss: 0.4126 - val_accuracy: 0.8755 - val_loss: 0.3405\n",
            "Epoch 14/15\n",
            "422/422 - 2s - 5ms/step - accuracy: 0.8558 - loss: 0.4037 - val_accuracy: 0.8722 - val_loss: 0.3546\n",
            "Epoch 15/15\n",
            "422/422 - 3s - 7ms/step - accuracy: 0.8580 - loss: 0.3975 - val_accuracy: 0.8700 - val_loss: 0.3495\n",
            "\n",
            "Evaluando en conjunto de prueba:\n",
            "Test loss: 0.3717\n",
            "Test accuracy: 0.8669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# MLP para Fashion MNIST - Versión Mejorada para Cumplir ILs\n",
        "# ===============================\n",
        "\n",
        "# -------------------------------\n",
        "# Sección 1: Importaciones y Configuración Inicial\n",
        "# -------------------------------\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt # Añadido para visualización\n",
        "from sklearn.metrics import classification_report # Añadido para métricas IL 1.4\n",
        "\n",
        "# Parámetros globales (Estos son HIPERPARÁMETROS CLAVE para experimentar - IL 1.1, IL 1.3)\n",
        "num_classes = 10         # Número de clases de salida (0-9)\n",
        "input_shape = (28, 28, 1)  # Forma de entrada para cada imagen\n",
        "batch_size = 128         # Tamaño de lote\n",
        "epochs = 15              # Número de épocas de entrenamiento\n",
        "learning_rate = 0.001    # Tasa de aprendizaje inicial para Adam\n",
        "dropout_rate = 0.5       # Tasa de Dropout (¡experimentar con este valor!)\n",
        "\n",
        "# -------------------------------\n",
        "# Sección 2: Carga y Preprocesamiento de Datos (IL 1.1)\n",
        "# -------------------------------\n",
        "# IL 1.1: Carga de datos\n",
        "print(\"Cargando dataset Fashion MNIST...\")\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "print(\"Dataset cargado.\")\n",
        "\n",
        "# IL 1.1: Preprocesamiento\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test  = x_test.astype(\"float32\")  / 255.0\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test  = np.expand_dims(x_test, -1)\n",
        "\n",
        "print(f\"Forma datos entrenamiento (x_train): {x_train.shape}, {x_train.shape[0]} muestras\")\n",
        "print(f\"Forma datos prueba (x_test): {x_test.shape}, {x_test.shape[0]} muestras\")\n",
        "\n",
        "# Guardar copias de las etiquetas de prueba para evaluación posterior (IL 1.4)\n",
        "y_test_labels = y_test.copy() # Guardar etiquetas originales (números 0-9)\n",
        "\n",
        "# IL 1.2: Preparación de etiquetas para 'categorical_crossentropy'/'softmax'\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(f\"Forma etiquetas entrenamiento (y_train): {y_train.shape}\")\n",
        "print(f\"Forma etiquetas prueba (y_test): {y_test.shape}\")\n",
        "\n",
        "# -------------------------------\n",
        "# Sección 3: Definición del Modelo MLP (IL 1.1, IL 1.2, IL 1.3)\n",
        "# -------------------------------\n",
        "# IL 1.1, IL 1.3: Implementación de un MLP usando Keras\n",
        "# **ACCIÓN REQUERIDA (Experimentación IL 1.1, IL 1.2):**\n",
        "#    - Para probar otras funciones de activación, cambia 'relu' por 'sigmoid', 'tanh', etc.\n",
        "#    - Para probar diferentes arquitecturas, cambia el número de capas o neuronas (ej: 128 -> 256).\n",
        "#    - Entrena un modelo por cada cambio y compara resultados.\n",
        "print(\"\\nDefiniendo la arquitectura del modelo MLP (Baseline)...\")\n",
        "model = keras.Sequential(name=\"mlp_fashion_mnist_baseline\")\n",
        "model.add(layers.Flatten(input_shape=input_shape))\n",
        "# IL 1.2: Uso de función de activación 'relu'\n",
        "model.add(layers.Dense(128, activation=\"relu\", name=\"hidden_layer_1\"))\n",
        "# IL 1.3: Uso de técnica de regularización 'Dropout'\n",
        "model.add(layers.Dropout(dropout_rate, name=\"dropout_1\")) # ¡Experimenta con dropout_rate!\n",
        "model.add(layers.Dense(64, activation=\"relu\", name=\"hidden_layer_2\"))\n",
        "model.add(layers.Dropout(dropout_rate, name=\"dropout_2\"))\n",
        "# IL 1.2: Uso de función de activación/salida 'softmax'\n",
        "model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\"))\n",
        "\n",
        "model.summary() # Útil para verificar la estructura y número de parámetros\n",
        "\n",
        "# -------------------------------\n",
        "# Sección 4: Compilación del Modelo (IL 1.2, IL 1.3, IL 1.4)\n",
        "# -------------------------------\n",
        "# IL 1.3: Selección de optimizador Adam\n",
        "# **ACCIÓN REQUERIDA (Experimentación IL 1.3):**\n",
        "#    - Prueba otros optimizadores (ej: keras.optimizers.SGD(learning_rate=...)).\n",
        "#    - Ajusta el 'learning_rate'.\n",
        "print(\"\\nCompilando el modelo...\")\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# IL 1.2: Selección de función de error 'categorical_crossentropy'\n",
        "# **ACCIÓN REQUERIDA (Experimentación IL 1.2):**\n",
        "#    - Si usas etiquetas numéricas (no one-hot), podrías usar 'sparse_categorical_crossentropy'.\n",
        "#    - Compara el impacto si cambias la función de error (aunque categorical_crossentropy es estándar aquí).\n",
        "# IL 1.4: Especificación de métrica 'accuracy' (se añadirán otras en evaluación)\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"] # Accuracy se calcula durante el entrenamiento/evaluación\n",
        ")\n",
        "print(\"Modelo compilado con éxito.\")\n",
        "\n",
        "# -------------------------------\n",
        "# Sección 5: Entrenamiento del Modelo (IL 1.1)\n",
        "# -------------------------------\n",
        "# IL 1.1: Ejecución del entrenamiento\n",
        "# **ACCIÓN REQUERIDA (Experimentación IL 1.1, IL 1.3):**\n",
        "#    - Ejecuta este bloque con diferentes 'batch_size' y 'epochs'.\n",
        "#    - Compara las curvas de aprendizaje (generadas más abajo) para cada experimento.\n",
        "print(f\"\\nIniciando entrenamiento por {epochs} épocas con tamaño de lote {batch_size}...\")\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.1, # Usa 10% para validación\n",
        "    verbose=2\n",
        ")\n",
        "print(\"Entrenamiento completado.\")\n",
        "\n",
        "# -------------------------------\n",
        "# Sección 6: Evaluación Detallada en el Conjunto de Prueba (IL 1.4)\n",
        "# -------------------------------\n",
        "# IL 1.4: Evalúa desempeño con accuracy, precision, recall, F1-Score\n",
        "print(\"\\nEvaluando en conjunto de prueba:\")\n",
        "# Paso 1: Obtener Loss y Accuracy base con evaluate()\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f\"Test loss (Pérdida): {score[0]:.4f}\")\n",
        "print(f\"Test accuracy (Exactitud): {score[1]:.4f}\")\n",
        "\n",
        "# Paso 2: Obtener predicciones para calcular otras métricas\n",
        "y_pred_prob = model.predict(x_test) # Obtiene probabilidades de salida\n",
        "y_pred_classes = np.argmax(y_pred_prob, axis=1) # Convierte probabilidades a clase predicha (0-9)\n",
        "\n",
        "# Paso 3: Calcular Precision, Recall, F1-Score usando classification_report\n",
        "# Necesitamos las etiquetas de prueba originales (0-9), no las one-hot\n",
        "print(\"\\nReporte de Clasificación (Precision, Recall, F1-Score por clase y promedios):\")\n",
        "# y_test_labels fue guardada antes del one-hot encoding\n",
        "print(classification_report(y_test_labels, y_pred_classes, digits=4))\n",
        "\n",
        "# **ACCIÓN REQUERIDA (IL 1.4):**\n",
        "#    - Crear un cuadro resumen en tu informe/notebook con Accuracy, Precision (promedio), Recall (promedio), F1-Score (promedio).\n",
        "#    - Interpretar estas métricas: ¿Qué clases clasifica bien/mal? ¿Hay desbalance?\n",
        "#    - Comparar estas métricas entre los diferentes modelos que entrenaste en tus experimentos.\n",
        "\n",
        "# -------------------------------\n",
        "# Sección 7: Visualización de Curvas de Aprendizaje (Análisis IL 1.1, IL 1.3)\n",
        "# -------------------------------\n",
        "# Útil para analizar el entrenamiento, detectar overfitting/underfitting y comparar experimentos\n",
        "print(\"\\nGenerando gráficos de curvas de aprendizaje...\")\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Gráfico de Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Accuracy Entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Accuracy Validación')\n",
        "plt.title('Accuracy por Época')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Gráfico de Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Loss Entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Loss Validación')\n",
        "plt.title('Loss por Época')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show() # Muestra los gráficos\n",
        "\n",
        "# **ACCIÓN REQUERIDA (Análisis y Comparación IL 1.1, IL 1.3):**\n",
        "#    - Analiza estas curvas: ¿Hay sobreajuste (gap grande entre train/val)? ¿El modelo converge?\n",
        "#    - Guarda estos gráficos para cada experimento que realices (ej., con diferente tasa de dropout, diferente # de épocas, etc.).\n",
        "#    - Presenta gráficos comparativos en tu informe/notebook para justificar cómo las técnicas de optimización (dropout) o los cambios de hiperparámetros afectaron el entrenamiento.\n",
        "\n",
        "# ===============================\n",
        "# Sección 8: Conclusiones y Próximos Pasos (Documentación)\n",
        "# ===============================\n",
        "# **ACCIÓN REQUERIDA:**\n",
        "#    - En tu cuaderno Jupyter, añade una sección final de Markdown para:\n",
        "#        - Resumir los resultados del MEJOR modelo encontrado tras la experimentación.\n",
        "#        - Discutir los hallazgos clave (qué funcionó, qué no, impacto de parámetros).\n",
        "#        - Comparar explícitamente diferentes configuraciones (tabla resumen es ideal).\n",
        "#        - Justificar las decisiones finales de arquitectura e hiperparámetros.\n",
        "#        - Reflexionar sobre posibles mejoras futuras.\n",
        "#\n",
        "# ¡Recuerda documentar CADA experimento que realices en tu cuaderno!\n",
        "# ===============================\n",
        "\n",
        "print(\"\\n--- Fin del Script ---\")"
      ],
      "metadata": {
        "id": "Cu6SaiTKr2w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 1. Introducción\n",
        "\n",
        "Este proyecto aborda un problema práctico de clasificación de imágenes utilizando una Red Neuronal Artificial (RNA) de tipo Perceptrón Multicapa (MLP). El objetivo es aplicar los fundamentos de Deep Learning para entrenar un modelo capaz de identificar diferentes tipos de artículos de moda a partir de imágenes en escala de grises.\n",
        "\n",
        "Para este propósito, utilizaremos el dataset **Fashion-MNIST**. Este conjunto de datos fue desarrollado por Zalando Research y se presenta como un reemplazo directo (\"drop-in replacement\") del clásico dataset MNIST de dígitos escritos a mano. Mientras que MNIST es un estándar ampliamente utilizado para la validación inicial de algoritmos de Machine Learning, Fashion-MNIST ofrece un desafío potencialmente mayor manteniendo la misma estructura y formato: un conjunto de entrenamiento de 60,000 imágenes y un conjunto de prueba de 10,000 imágenes, todas ellas en escala de grises y de tamaño 28x28 píxeles, distribuidas en 10 clases distintas.\n",
        "\n",
        "La elección de Fashion-MNIST nos permite trabajar con un dataset estandarizado, bien conocido en la comunidad, pero que requiere que el modelo aprenda características más complejas que las presentes en los dígitos manuscritos. El objetivo final de este encargo es implementar, entrenar, optimizar y evaluar un MLP utilizando TensorFlow/Keras para clasificar correctamente las imágenes de artículos de moda de este dataset, cumpliendo con los indicadores de logro especificados en la evaluación.\n",
        "\n",
        "*Fuente oficial del dataset: [https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)*\n",
        "\n",
        "## 2. Descripción del Dataset (Contenido)\n",
        "\n",
        "El dataset Fashion-MNIST se compone de imágenes y sus correspondientes etiquetas de clase. A continuación, se detallan sus características principales:\n",
        "\n",
        "*   **Dimensiones de la Imagen:** Cada imagen tiene una altura de 28 píxeles y un ancho de 28 píxeles, resultando en un total de 784 píxeles por imagen.\n",
        "*   **Formato de Píxeles:** Las imágenes están en escala de grises. Cada píxel tiene asociado un único valor numérico entero que indica su nivel de oscuridad. Este valor varía entre 0 (blanco) y 255 (negro). Valores más altos representan píxeles más oscuros.\n",
        "*   **Estructura de los Datos:** Cada Fila del Dataset representa una imagen:\n",
        "    *   **Primera Columna:** Corresponde a la etiqueta de clase (un número del 0 al 9) que identifica el tipo de artículo de moda representado en la imagen.\n",
        "    *   **Columnas Restantes (784):** Contienen los valores de los píxeles (0-255) de la imagen asociada, generalmente desplegados en un formato aplanado (vector de 784 elementos).\n",
        "*   **Etiquetas de Clase:** Cada ejemplo (imagen) está asignado a una de las siguientes 10 clases, representadas por un número entero:\n",
        "\n",
        "    *   `0`: T-shirt/top (Camiseta/Top)\n",
        "    *   `1`: Trouser (Pantalón)\n",
        "    *   `2`: Pullover (Suéter)\n",
        "    *   `3`: Dress (Vestido)\n",
        "    *   `4`: Coat (Abrigo)\n",
        "    *   `5`: Sandal (Sandalia)\n",
        "    *   `6`: Shirt (Camisa)\n",
        "    *   `7`: Sneaker (Zapatilla deportiva)\n",
        "    *   `8`: Bag (Bolso)\n",
        "    *   `9`: Ankle boot (Botín)\n",
        "\n",
        "**En resumen:** Cada fila del dataset representa una imagen de 28x28 píxeles en escala de grises, junto con una etiqueta numérica que indica a cuál de las 10 categorías de ropa pertenece. El objetivo del modelo será aprender a predecir esta etiqueta basándose en los 784 valores de píxeles de entrada.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "DZJqnXR5tqtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 3. Configuración del Entorno y Selección del Framework\n",
        "\n",
        "Antes de proceder con la carga y preprocesamiento de los datos, es fundamental definir el entorno de trabajo y las herramientas principales que se utilizarán para la implementación de la Red Neuronal Artificial (MLP).\n",
        "\n",
        "### 3.1. Elección del Framework: TensorFlow con Keras\n",
        "\n",
        "Para el desarrollo de este proyecto, hemos seleccionado **TensorFlow (versión X.Y.Z)** como la biblioteca principal de Deep Learning, utilizando específicamente su interfaz de alto nivel **Keras**.\n",
        "\n",
        "**Justificación de la Decisión:**\n",
        "\n",
        "La elección de TensorFlow con Keras se basa en las siguientes consideraciones clave, alineadas con los objetivos de la evaluación y los requisitos del proyecto:\n",
        "\n",
        "1.  **Facilidad de Uso y Desarrollo Rápido (API de Keras):** Keras proporciona una API intuitiva y modular que simplifica significativamente el proceso de definición, entrenamiento y evaluación de redes neuronales, incluyendo los MLP requeridos. Esto nos permite centrarnos en la aplicación de los conceptos fundamentales de Deep Learning (como la arquitectura del modelo, funciones de activación, optimizadores y métricas) en lugar de en detalles de implementación de bajo nivel.\n",
        "2.  **Cumplimiento de Requisitos:** TensorFlow/Keras ofrece todas las componentes necesarias para abordar los Indicadores de Logro de esta evaluación:\n",
        "    *   Capas densas para construir el MLP.\n",
        "    *   Amplia variedad de funciones de activación  y la flexibilidad para definir funciones personalizadas si fuera necesario .\n",
        "    *   Diversas funciones de pérdida adecuadas para problemas de clasificación.\n",
        "    *   Múltiples algoritmos de optimización para entrenar y optimizar el modelo.\n",
        "    *   Herramientas integradas para la evaluación del modelo y el cálculo de métricas.\n",
        "3.  **Documentación Extensa y Comunidad Activa:** TensorFlow y Keras cuentan con una documentación oficial muy completa, numerosos tutoriales y una vasta comunidad de usuarios. Esto facilita la resolución de dudas y la consulta de ejemplos durante el desarrollo.\n",
        "4.  **Integración con Ecosistema:** TensorFlow se integra fácilmente con otras herramientas útiles del ecosistema de Data Science en Python, como NumPy, Pandas y Scikit-learn (que utilizaremos para la carga y preprocesamiento de datos), así como con herramientas de visualización como Matplotlib/Seaborn y TensorBoard (para un análisis más profundo del entrenamiento, si se requiere).\n",
        "5.  **Entorno de Ejecución (Google Colab):** TensorFlow está preinstalado y optimizado para su uso en Google Colab, el entorno recomendado para este proyecto, permitiendo aprovechar fácilmente los recursos de hardware como GPUs o TPUs para acelerar el entrenamiento si fuera necesario.\n",
        "\n",
        "**En resumen**, la combinación TensorFlow/Keras representa un balance adecuado entre potencia, flexibilidad y facilidad de uso, lo que la convierte en una opción idónea para implementar eficientemente el MLP solicitado y cumplir con los objetivos de esta evaluación dentro del plazo establecido. Las siguientes secciones detallarán cómo se utiliza este framework para la carga, preprocesamiento, modelado y evaluación.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "9keVEug9tuLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importación de Librerías\n",
        "\n"
      ],
      "metadata": {
        "id": "sT1sqWuGtyLG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aKn2eqPfsECZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparando los Datos"
      ],
      "metadata": {
        "id": "HSL5XHaPzdNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Definición del Modelo (Arquitectura CNN)\n",
        "En esta sección, definimos la arquitectura de nuestra red neuronal utilizando la API Sequential de Keras. Nota: Este modelo es una Red Neuronal Convolucional (CNN), que incluye capas especializadas para procesar datos espaciales como las imágenes."
      ],
      "metadata": {
        "id": "LkRhS4eR1pSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Compilación del Modelo\n",
        "Antes de poder entrenar el modelo, necesitamos configurarlo mediante el método compile. Este paso define la función de pérdida que se minimizará, el optimizador que se usará para ajustar los pesos del modelo, y las métricas que queremos monitorizar durante el entrenamiento y la evaluación."
      ],
      "metadata": {
        "id": "HY95eqH-1zd9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Evaluación del Modelo en el Conjunto de Prueba\n",
        "Una vez que el modelo ha sido entrenado, el siguiente paso crucial es evaluar su rendimiento en el conjunto de prueba (x_test, y_test). Este conjunto contiene datos que el modelo no ha visto durante el proceso de entrenamiento ni durante la fase de validación (si se usó validation_split en fit). Esta evaluación nos proporciona una estimación imparcial de cómo se espera que el modelo generalice a nuevos datos desconocidos."
      ],
      "metadata": {
        "id": "WS-FhbP1AJKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entre los dos resultados:\n",
        "\n",
        "| Enfoque | Test Loss | Test Accuracy |\n",
        "|---------|-----------|---------------|\n",
        "| **CNN** | 0.2407    | **0.9128**    |\n",
        "| **MLP** | 0.3717    | 0.8669        |\n",
        "\n",
        "- **Exactitud (accuracy)**: la CNN alcanza un 91.28 %, frente al 86.69 % del MLP, es decir una ganancia de ≈ 4.6 puntos porcentuales.  \n",
        "- **Pérdida (loss)**: la CNN obtiene un valor más bajo (0.2407 vs 0.3717), lo que indica que sus predicciones están más cercanas a las distribuciones reales de las clases.\n",
        "\n",
        "**Conclusión:** la arquitectura **CNN** ofrece mejores métricas en clasificación de Fashion MNIST, gracias a su capacidad de explotar las estructuras espaciales de las imágenes (convoluciones y pooling) antes de llegar a la capa densa final. Si tu objetivo es maximizar precisión en datos de imagen, la CNN es la opción más adecuada."
      ],
      "metadata": {
        "id": "3jLyKG9HEP-G"
      }
    }
  ]
}